import feedparser
from deep_translator import GoogleTranslator
import json
import os
import datetime
import time

# è®¾ç½®æ—¶åŒºä¸º UTC+9 (æ—¥æœ¬æ—¶é—´)
# GitHub Actions æœåŠ¡å™¨é€šå¸¸æ˜¯ UTC+0ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ +9
JST_OFFSET = datetime.timedelta(hours=9)

RSS_URL = "https://news.yahoo.co.jp/rss/topics/top-picks.xml"

def get_current_jst_time():
    return datetime.datetime.utcnow() + JST_OFFSET

def update_news():
    print("ğŸš€ å¼€å§‹æŠ“å– Yahoo Japan RSS...")
    try:
        feed = feedparser.parse(RSS_URL)
    except Exception as e:
        print(f"âŒ RSSæŠ“å–å¤±è´¥: {e}")
        return

    translator = GoogleTranslator(source='auto', target='zh-CN')
    
    news_data = []
    
    # æŠ“å–å‰ 15 æ¡
    for entry in feed.entries[:15]:
        try:
            # ç¿»è¯‘æ ‡é¢˜
            zh_title = translator.translate(entry.title)
        except:
            zh_title = entry.title
        
        # æå–å‘å¸ƒæ—¶é—´ (å°è¯•è§£æ RSS çš„æ—¶é—´ï¼Œå¦‚æœå¤±è´¥åˆ™ç”¨å½“å‰æ—¶é—´)
        try:
            if hasattr(entry, 'published_parsed') and entry.published_parsed:
                # è½¬æ¢ä¸º JST æ—¶é—´æ˜¾ç¤º
                published_utc = datetime.datetime(*entry.published_parsed[:6])
                published_jst = published_utc # Yahoo RSSé€šå¸¸å·²ç»æ˜¯æ—¶åŒºè°ƒæ•´è¿‡çš„ï¼Œæˆ–è€…æˆ‘ä»¬åªå–æ—¶åˆ†
                time_str = published_jst.strftime("%H:%M")
            else:
                time_str = get_current_jst_time().strftime("%H:%M")
        except:
            time_str = get_current_jst_time().strftime("%H:%M")

        news_data.append({
            "title": zh_title,
            "origin": entry.title,
            "link": entry.link,
            "time": time_str
        })
        # ç¨å¾®æš‚åœé˜²å°
        time.sleep(0.5)

    if not news_data:
        print("âš ï¸ æœªè·å–åˆ°ä»»ä½•æ–°é—»æ•°æ®")
        return

    # --- 1. ä¿å­˜ä»Šæ—¥æœ€æ–°æ•°æ® (ä¾›é¦–é¡µé»˜è®¤æ˜¾ç¤º) ---
    with open('data.json', 'w', encoding='utf-8') as f:
        json.dump(news_data, f, ensure_ascii=False, indent=2)
    print("âœ… data.json æ›´æ–°æˆåŠŸ")

    # --- 2. ä¿å­˜å†å²å­˜æ¡£ (archive/YYYY-MM-DD.json) ---
    # ç¡®ä¿ archive æ–‡ä»¶å¤¹å­˜åœ¨
    archive_dir = "archive"
    if not os.path.exists(archive_dir):
        os.makedirs(archive_dir)
    
    # è·å–æ—¥æœ¬æ—¶é—´çš„æ—¥æœŸå­—ç¬¦ä¸² (ä¾‹å¦‚ 2023-11-28)
    date_str = get_current_jst_time().strftime("%Y-%m-%d")
    archive_path = os.path.join(archive_dir, f"{date_str}.json")

    # å†™å…¥å­˜æ¡£
    with open(archive_path, 'w', encoding='utf-8') as f:
        json.dump(news_data, f, ensure_ascii=False, indent=2)
    print(f"âœ… å†å²å­˜æ¡£å·²æ›´æ–°: {archive_path}")

if __name__ == "__main__":
    update_news()